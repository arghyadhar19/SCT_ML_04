# SCT_ML_04

# ğŸ¤– Hand Gesture Recognition using CNN

This project implements a **Convolutional Neural Network (CNN)** to recognize static hand gestures from the **LeapGestRecog** dataset. It includes data loading, preprocessing, model training, evaluation, and test image prediction â€” all using Python, OpenCV, TensorFlow, and Matplotlib.

---

## ğŸ“‚ Dataset

**LeapGestRecog** from Kaggle:  .(https://www.kaggle.com/datasets/gti-upm/leapgestrecog).
Each gesture class is organized in folders under user IDs (e.g., `01`, `02`, etc.).

/leapGestRecog/
â”œâ”€â”€ 01/
â”‚ â”œâ”€â”€ 01_palm/
â”‚ â”‚ â”œâ”€â”€ img_1.png
â”‚ â”‚ â”œâ”€â”€ ...
â”‚ â””â”€â”€ ...
â””â”€â”€ ...


> âœ… Only one user folder (`01`) is used for simplicity. You can expand to more users.

---

## ğŸš€ Workflow

1. ğŸ“ Load grayscale gesture images
2. ğŸ”– Label gestures using folder names
3. âš™ï¸ Normalize and reshape input
4. ğŸ§  Train CNN on image data
5. ğŸ“Š Evaluate test accuracy
6. ğŸ” Predict and visualize user-provided image

---

## ğŸ§  Model Architecture

```python
Sequential([
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])
```
pip install tensorflow opencv-python matplotlib numpy
